{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSTM -\n",
    "Generative Models to mimic writing style of prominent Bertrand Russell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_newlines(sentence):\n",
    "    new_sentence = re.sub(r'\\\\r\\\\n', ' ', sentence)\n",
    "    return new_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_header(sentence):\n",
    "    new_sentence = ' '\n",
    "    if(sentence[:11] == \"b'xefxbbxbf\"):\n",
    "        new_sentence = sentence[11:]\n",
    "    elif(sentence[:10] == \"bxefxbbxbf\"):\n",
    "        new_sentence = sentence[10:]\n",
    "    elif(sentence[:2] == \"b'\"):\n",
    "        new_sentence = sentence[2:]\n",
    "    else:\n",
    "        pass\n",
    "    return new_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_end(sentence):\n",
    "    new_sentence = ' '\n",
    "    if(sentence[-2:] == \" '\"):\n",
    "        new_sentence = sentence[:-2]\n",
    "    return new_sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def to_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_punct(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(\"[^a-zA-Z' ]+\", '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_controls(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if(word[:1] != chr(92) and word != ''):\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            pass\n",
    "    return new_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_roman_numerals(words):\n",
    "    roman_num = ['i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x',\n",
    "                 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X']\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if(word not in roman_num and word != ''):\n",
    "            new_words.append(word)\n",
    "        else:\n",
    "            pass\n",
    "    return new_words\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def to_lower(words):\n",
    "    new_words =[]\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def back_to_string(words):\n",
    "    sentences = []\n",
    "    text = ' '\n",
    "    for word in words:\n",
    "        sentence = ' '.join(word)\n",
    "        sentences.append(sentence)\n",
    "    text = ' '.join(sentences)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    sentences = text.split('.')\n",
    "    new_words = []\n",
    "    for sentence in sentences:\n",
    "        new_sentence = re.sub(r'\\\\r\\\\n', ' ', sentence)\n",
    "        words = new_sentence.split()\n",
    "        words = remove_controls(words)\n",
    "        words = to_ascii(words)\n",
    "        words = remove_roman_numerals(words)\n",
    "        words = remove_punct(words)\n",
    "        words = to_lower(words)\n",
    "        if(len(words) != 0):\n",
    "            new_words.append(words)\n",
    "        else:\n",
    "            pass\n",
    "    text = back_to_string(new_words)\n",
    "    text = remove_header(text)\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unique_alpha(text):\n",
    "    unique = ''\n",
    "    for c in text:\n",
    "        unique = set(c)\n",
    "    return unique"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scale(text):\n",
    "    scaled = (text - text.min()) / (text.max() - text.min())\n",
    "    return scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_to_ord(text):\n",
    "    result = []\n",
    "    for char in text:\n",
    "        result.append(ord(char))\n",
    "    result = pd.Series(result)\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "titles = ['MLOE.txt','TAMatter.txt', 'OKEWFSMP.txt', 'TPP.txt', 'THWP.txt', 'TAM.txt', 'AIIMAT.txt']\n",
    "cleaned_texts = []\n",
    "for t in titles:\n",
    "    f = open(t, 'rb')\n",
    "    s = str(f.read())\n",
    "    f.close()\n",
    "    cleaned_texts.append(clean_text(s))\n",
    "\n",
    "cleaned_texts[6] = cleaned_texts[6][:-15]\n",
    "cleaned_texts[0] = cleaned_texts[0][:-2]\n",
    "cleaned_texts[1] = cleaned_texts[1][:-2]\n",
    "cleaned_texts[2] = cleaned_texts[2][:-2]\n",
    "cleaned_texts[4] = cleaned_texts[4][:-2]\n",
    "cleaned_texts[5] = cleaned_texts[5][:-2]\n",
    "\n",
    "corpus = ' '.join(cleaned_texts)\n",
    "\n",
    "chars = list(set(corpus))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "corpus_converted = convert_to_ord(corpus)\n",
    "corpus_scaled = scale(corpus_converted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "window = 100\n",
    "stride = 1\n",
    "\n",
    "string = []\n",
    "next_char = []\n",
    "\n",
    "for i in range(0, (len(corpus_scaled) - window), stride):\n",
    "    string.append(corpus_scaled[i : (i + window)])\n",
    "    next_char.append(corpus[(i + window)])\n",
    "\n",
    "x = np.reshape(string, (len(string), window, 1))\n",
    "y = OneHotEncoder().fit_transform(np.array(next_char).reshape(-1, 1)).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory_units = len(chars)\n",
    "model = Sequential()\n",
    "model.add(LSTM(memory_units, input_shape = (x.shape[1], x.shape[2])))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', mode = 'min')\n",
    "callbacks_set = [checkpoint]\n",
    "\n",
    "model.fit(x, y, batch_size = 64, epochs = 60, callbacks = callbacks_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-47-2.33.hdf5\"\n",
    "model.load_weights(filename)\n",
    "\n",
    "input_string = \"there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to  emphasize the ojbect\"\n",
    "\n",
    "length = 1000\n",
    "output = ''\n",
    "for i in range(length):\n",
    "    input_converted = convert_to_ord(input_string[i : (window + i)])\n",
    "    input_scaled = scale(input_converted)\n",
    "    x_ = np.array(input_scaled).reshape(1, -1)\n",
    "    x_ = np.reshape(x_, (1, window, 1))\n",
    "    pred = model.predict(x_, verbose = 0)\n",
    "    index = np.argmax(pred)\n",
    "    result = int_to_char[index]\n",
    "    output += result\n",
    "    input_string += result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape = (x.shape[1], x.shape[2])))\n",
    "model2.add(Dropout(.2))\n",
    "model2.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model2.compile(loss = 'categorical_crossentropy', optimizer = 'Adam')\n",
    "filepath2 = \"model2/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint2 = ModelCheckpoint(filepath2, monitor = 'loss', mode = 'min')\n",
    "callbacks_set2 = [checkpoint2]\n",
    "\n",
    "model2.fit(x, y, batch_size = 64, epochs = 30, callbacks = callbacks_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename2 = \"weights-improvement-06-1.93.hdf5\"\n",
    "model2.load_weights(filename2)\n",
    "\n",
    "input_string2 = \"there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to  emphasize the ojbect\"\n",
    "\n",
    "length = 1000\n",
    "output2 = ''\n",
    "for i in range(length):\n",
    "    input_converted2 = convert_to_ord(input_string[i : (window + i)])\n",
    "    input_scaled2 = scale(input_converted)\n",
    "    x_2 = np.array(input_scaled2).reshape(1, -1)\n",
    "    x_2 = np.reshape(x_, (1, window, 1))\n",
    "    pred2 = model2.predict(x_2, verbose = 0)\n",
    "    index2 = np.argmax(pred2)\n",
    "    result2 = int_to_char[index2]\n",
    "    output2 += result2\n",
    "    input_string2 += result2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output2\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}